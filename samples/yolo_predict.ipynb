{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-28T19:17:37.965124700Z",
     "start_time": "2024-02-28T19:17:36.105059600Z"
    }
   },
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from tqdm import tqdm\n",
    "\n",
    "import glob as glob\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "with open('../eduset/yolo/config.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "    \n",
    "out_dictionary = data[\"config\"][\"OUT_DIR\"]\n",
    "resize_to = data[\"config\"][\"RESIZE_TO\"]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T19:17:40.041182300Z",
     "start_time": "2024-02-28T19:17:40.036182Z"
    }
   },
   "id": "a9c56493f78c3979"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model_path = \"../samples/yolo_runs/model/model_v12/weights/best.pt\"\n",
    "model = YOLO(model_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T19:17:49.252563600Z",
     "start_time": "2024-02-28T19:17:49.166617300Z"
    }
   },
   "id": "93c923a18cd964a8"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to stack",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m images \u001B[38;5;241m=\u001B[39m glob\u001B[38;5;241m.\u001B[39mglob(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../samples/Eduset-One-Dataset-1/test/images/*.jpg\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m results \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(conf\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.25\u001B[39m,\n\u001B[1;32m      3\u001B[0m                         source\u001B[38;5;241m=\u001B[39mimages,\n\u001B[1;32m      4\u001B[0m                         save\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[1;32m      5\u001B[0m                         project\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mout_dictionary\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m      6\u001B[0m                         name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimages\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/object-detection/lib/python3.11/site-packages/ultralytics/engine/model.py:429\u001B[0m, in \u001B[0;36mModel.predict\u001B[0;34m(self, source, stream, predictor, **kwargs)\u001B[0m\n\u001B[1;32m    427\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m prompts \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mset_prompts\u001B[39m\u001B[38;5;124m\"\u001B[39m):  \u001B[38;5;66;03m# for SAM-type models\u001B[39;00m\n\u001B[1;32m    428\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor\u001B[38;5;241m.\u001B[39mset_prompts(prompts)\n\u001B[0;32m--> 429\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor\u001B[38;5;241m.\u001B[39mpredict_cli(source\u001B[38;5;241m=\u001B[39msource) \u001B[38;5;28;01mif\u001B[39;00m is_cli \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpredictor(source\u001B[38;5;241m=\u001B[39msource, stream\u001B[38;5;241m=\u001B[39mstream)\n",
      "File \u001B[0;32m~/anaconda3/envs/object-detection/lib/python3.11/site-packages/ultralytics/engine/predictor.py:204\u001B[0m, in \u001B[0;36mBasePredictor.__call__\u001B[0;34m(self, source, model, stream, *args, **kwargs)\u001B[0m\n\u001B[1;32m    202\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream_inference(source, model, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 204\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstream_inference(source, model, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs))\n",
      "File \u001B[0;32m~/anaconda3/envs/object-detection/lib/python3.11/site-packages/torch/utils/_contextlib.py:35\u001B[0m, in \u001B[0;36m_wrap_generator.<locals>.generator_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;66;03m# Issuing `None` to a generator fires it up\u001B[39;00m\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m---> 35\u001B[0m         response \u001B[38;5;241m=\u001B[39m gen\u001B[38;5;241m.\u001B[39msend(\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     38\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     39\u001B[0m             \u001B[38;5;66;03m# Forward the response to our caller and get its next request\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/object-detection/lib/python3.11/site-packages/ultralytics/engine/predictor.py:279\u001B[0m, in \u001B[0;36mBasePredictor.stream_inference\u001B[0;34m(self, source, model, *args, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;66;03m# Preprocess\u001B[39;00m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m profilers[\u001B[38;5;241m0\u001B[39m]:\n\u001B[0;32m--> 279\u001B[0m     im \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess(im0s)\n\u001B[1;32m    281\u001B[0m \u001B[38;5;66;03m# Inference\u001B[39;00m\n\u001B[1;32m    282\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m profilers[\u001B[38;5;241m1\u001B[39m]:\n",
      "File \u001B[0;32m~/anaconda3/envs/object-detection/lib/python3.11/site-packages/ultralytics/engine/predictor.py:122\u001B[0m, in \u001B[0;36mBasePredictor.preprocess\u001B[0;34m(self, im)\u001B[0m\n\u001B[1;32m    120\u001B[0m not_tensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(im, torch\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[1;32m    121\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m not_tensor:\n\u001B[0;32m--> 122\u001B[0m     im \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mstack(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpre_transform(im))\n\u001B[1;32m    123\u001B[0m     im \u001B[38;5;241m=\u001B[39m im[\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, ::\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mtranspose((\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m))  \u001B[38;5;66;03m# BGR to RGB, BHWC to BCHW, (n, 3, h, w)\u001B[39;00m\n\u001B[1;32m    124\u001B[0m     im \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mascontiguousarray(im)  \u001B[38;5;66;03m# contiguous\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/object-detection/lib/python3.11/site-packages/numpy/core/shape_base.py:445\u001B[0m, in \u001B[0;36mstack\u001B[0;34m(arrays, axis, out, dtype, casting)\u001B[0m\n\u001B[1;32m    443\u001B[0m arrays \u001B[38;5;241m=\u001B[39m [asanyarray(arr) \u001B[38;5;28;01mfor\u001B[39;00m arr \u001B[38;5;129;01min\u001B[39;00m arrays]\n\u001B[1;32m    444\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m arrays:\n\u001B[0;32m--> 445\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mneed at least one array to stack\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m    447\u001B[0m shapes \u001B[38;5;241m=\u001B[39m {arr\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;28;01mfor\u001B[39;00m arr \u001B[38;5;129;01min\u001B[39;00m arrays}\n\u001B[1;32m    448\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(shapes) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "\u001B[0;31mValueError\u001B[0m: need at least one array to stack"
     ]
    }
   ],
   "source": [
    "images = glob.glob(\"../samples/Eduset-One-Dataset-2/test/images/*.jpg\")\n",
    "results = model.predict(conf=0.25,\n",
    "                        source=images,\n",
    "                        save=True,\n",
    "                        project=f\"{out_dictionary}\",\n",
    "                        name=\"images\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T19:17:51.871633400Z",
     "start_time": "2024-02-28T19:17:50.945681800Z"
    }
   },
   "id": "79aba3f874152077"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "video = \"../samples/images/video.mp4\"\n",
    "video_predict = model.predict(conf=0.8,\n",
    "                              source=video,\n",
    "                              save=True,\n",
    "                              project=f\"{out_dictionary}\",\n",
    "                              name=\"videos\",\n",
    "                              verbose=False,\n",
    "                              show=False, \n",
    "                              stream=True\n",
    "                              )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T19:18:04.824218500Z",
     "start_time": "2024-02-28T19:18:04.780245200Z"
    }
   },
   "id": "7b55b2256e325e0e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4451frame [02:30, 28.44frame/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results saved to \u001B[1m../samples/yolo_runs/videos\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4285frame [02:30, 28.55frame/s]\n"
     ]
    }
   ],
   "source": [
    "# [Solved] https://github.com/ultralytics/ultralytics/issues/1869\n",
    "# Saving longer video\n",
    "progress_bar = tqdm(video_predict, unit=\"frame\")\n",
    "for _ in progress_bar:\n",
    "    progress_bar.update(1)\n",
    "\n",
    "progress_bar.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-28T19:20:41.644411200Z",
     "start_time": "2024-02-28T19:18:11.570088700Z"
    }
   },
   "id": "8d34e1f40ac6b108"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-26T14:36:15.957105800Z",
     "start_time": "2024-02-26T14:36:15.947585200Z"
    }
   },
   "id": "4c8d3361039bf685"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
